{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Call to RAWG gaming database.\n",
    "# Running this will take over an hour... you've been warned.\n",
    "dictionary_list = []\n",
    "for i in range(2500):\n",
    "    url = f'https://api.rawg.io/api/games?key=087fec04dc43483d8057bacd2bd5be04&page_size=40&page={i+1}'\n",
    "    response = requests.get(url).json()\n",
    "    dictionary_list = dictionary_list + response['results']\n",
    "    print (f'Page {i+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353661a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(dictionary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59caf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b716ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Api call to Steam Spy dataset.\n",
    "name = []\n",
    "postive = []\n",
    "negative = []\n",
    "owners = []\n",
    "price = []\n",
    "publisher = []\n",
    "for i in range(51):\n",
    "    url = f'https://steamspy.com/api.php?request=all&page={i+1}'\n",
    "    response = requests.get(url).json()\n",
    "    for j in response:\n",
    "        name.append(response[j]['name'])\n",
    "        postive.append(response[j]['positive'])\n",
    "        negative.append(response[j]['negative'])\n",
    "        owners.append(response[j]['owners'])\n",
    "        price.append(response[j]['initialprice'])\n",
    "        publisher.append(response[j]['publisher'])\n",
    "    #dictionary_list = dictionary_list + response['results']\n",
    "    print (f'Page {i+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating df from result lists from API call.\n",
    "steam_df = pd.DataFrame({'name': name, 'postive' : postive, 'negative' : negative, 'owners' : owners, 'price' : price, 'publisher' : publisher})\n",
    "steam_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to save data\n",
    "steam_df.to_csv('steam_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have dataset.\n",
    "steam_df = pd.read_csv ('steam_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8495f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged to combine steam data with original dateframe.\n",
    "merged_df = pd.merge(df, steam_df, how='inner', left_on = 'name', right_on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b557430",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023be00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv ('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacf8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning unecessary columns.\n",
    "drop_columns = ['id', 'slug', 'tba',\n",
    "       'rating', 'rating_top', 'ratings', 'ratings_count',\n",
    "       'reviews_text_count', 'added', 'metacritic', 'playtime',\n",
    "       'suggestions_count', 'updated', 'user_game', 'reviews_count',\n",
    "       'saturated_color', 'dominant_color', \n",
    "       'stores', 'clip', 'short_screenshots',\n",
    "       'added_by_status.yet', 'added_by_status.owned',\n",
    "       'added_by_status.beaten', 'added_by_status.toplay',\n",
    "       'added_by_status.dropped', 'added_by_status.playing', \n",
    "       'esrb_rating.name', 'esrb_rating.slug', 'esrb_rating',\n",
    "       'community_rating', 'added_by_status', 'platforms', 'publisher']\n",
    "merged_df.drop(drop_columns, inplace=True, axis=1)\n",
    "\n",
    "#'Unnamed: 0', 'Unnamed: 0.1',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total reviews to then find total positive reviews as a % (our target)\n",
    "merged_df['total_reviews'] = merged_df['postive'] + merged_df['negative']\n",
    "merged_df['review_score'] = merged_df['postive'] / merged_df['total_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns2 = ['postive', 'negative']\n",
    "merged_df.drop(drop_columns2, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe97bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns3 = ['Unnamed: 0_y', 'Unnamed: 0_x']\n",
    "merged_df.drop(drop_columns3, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming combined dataset back to df.\n",
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the format is correctly datetime, then splitting the release month (the value we thought would be most relevant to it's review score).\n",
    "df['released'] = pd.to_datetime(df['released'], format = '%Y-%m-%dT', errors = 'coerce')\n",
    "df['released_month'] = df['released'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the lists needed to gather the data.\n",
    "# The _list variable will store the complete data from each stated column.\n",
    "# Each game has their own list of Genres, Tags, and Original Release Platforms\n",
    "# The _names for genre and platforms are used to collect the unique values for making the new columns\n",
    "# The _count for tags are used to see which tags are used most frequently\n",
    "platforms_list = []\n",
    "platforms_name = []\n",
    "tags_list =[]\n",
    "tags_count = []\n",
    "genres_list = []\n",
    "genres_names = []\n",
    "\n",
    "# This reads through the entire dataframe.\n",
    "# Saves each column's value and reads the value properly as a dictionary.\n",
    "for i in range(len(df.index)):\n",
    "    game_plat = df.parent_platforms[i]\n",
    "    game_tag = df.tags[i]\n",
    "    game_name = df.genres[i]\n",
    "\n",
    "    game_plat_dict = ast.literal_eval(game_plat)\n",
    "    game_tag_dict = ast.literal_eval(game_tag)\n",
    "    game_name_dict = ast.literal_eval(game_name)\n",
    "\n",
    "    # These short-lived variables are constantly tracking each games indvidual values and then adding them to the main lists.\n",
    "    platforms = []\n",
    "    genres = []\n",
    "    tags = []\n",
    "\n",
    "    # Because each column (genre, tag, and platform) was organized into a dictionary of variable length, these loops\n",
    "    # are used to read through them and grab the relevant 'name' values.\n",
    "    for j in range(len(game_plat_dict)):\n",
    "        platforms.append(game_plat_dict[j]['platform']['name'])\n",
    "        if game_plat_dict[j]['platform']['name'] not in platforms_name:\n",
    "            platforms_name.append(game_plat_dict[j]['platform']['name'])\n",
    "    platforms.sort()\n",
    "    platforms_list.append(platforms)\n",
    "\n",
    "    for k in range(len(game_tag_dict)):\n",
    "        tags.append(game_tag_dict[k]['name'])\n",
    "        tags_count.append(game_tag_dict[k]['name'])\n",
    "    tags.sort()\n",
    "    tags_list.append(tags)\n",
    "\n",
    "    for l in range(len(game_name_dict)):\n",
    "        genres.append(game_name_dict[l]['name'])\n",
    "        if game_name_dict[l]['name'] not in genres_names:\n",
    "            genres_names.append(game_name_dict[l]['name'])\n",
    "    genres.sort()\n",
    "    genres_names.sort(reverse=True)\n",
    "    genres_list.append(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tags were each collected into one giant pool. This then sorts them and counts them.\n",
    "from collections import Counter\n",
    "tags_dict = Counter(tags_count)\n",
    "\n",
    "sorted_tags = {}\n",
    "sorted_keys = sorted(tags_dict, key=tags_dict.get, reverse=True) \n",
    "\n",
    "for w in sorted_keys:\n",
    "    sorted_tags[w] = tags_dict[w]\n",
    "\n",
    "# Here the sorted keys are then filtered.  First the top 25 most common were selected, but anything directly\n",
    "# Steam related was removed as it did not seem a relevant selling or scoring point to a game.\n",
    "# RPG tag was removed as well as it is already tracked as a genre.\n",
    "tag_keys = list(sorted_tags.keys())\n",
    "filtered_tag_keys = tag_keys[:25]\n",
    "for key in filtered_tag_keys:\n",
    "    if \"steam\" in key.lower():\n",
    "        filtered_tag_keys.remove(key)\n",
    "filtered_tag_keys.remove('RPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the columns so games data could displayed.\n",
    "for platform in platforms_name:\n",
    "    df.insert(1,f\"platform_{platform.lower()}\",0)\n",
    "\n",
    "for tag in filtered_tag_keys:\n",
    "    df.insert(1,f\"tag_{tag.lower()}\",0)\n",
    "\n",
    "for genre in genres_names:\n",
    "    df.insert(1,f\"genre_{genre.lower()}\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24509f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally reading the organized data back into each game.\n",
    "# Each of the possible genres, tags, and platforms are added as columns to dataset and games populate the values appropriately.\n",
    "for i in range(len(platforms_list)):\n",
    "    for j in range(len(platforms_list[i])):\n",
    "        for k in range(len(platforms_name)):\n",
    "            if platforms_list[i][j] == platforms_name[k]:\n",
    "                df.at[i,f'platform_{platforms_name[k].lower()}'] = 1\n",
    "\n",
    "for i in range(len(tags_list)):\n",
    "    for j in range(len(tags_list[i])):\n",
    "        for k in range(len(filtered_tag_keys)):\n",
    "            if tags_list[i][j] == filtered_tag_keys[k]:\n",
    "                df.at[i,f\"tag_{filtered_tag_keys[k].lower()}\"] = 1\n",
    "\n",
    "\n",
    "for i in range(len(genres_list)):\n",
    "    for j in range(len(genres_list[i])):\n",
    "        for k in range(len(genres_names)):\n",
    "            if genres_list[i][j] == genres_names[k]:\n",
    "                df.at[i,f'genre_{genres_names[k].lower()}'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the parent columns now that we extracted the necessary dictionary values.\n",
    "df = df.drop(columns=['genres', 'tags','parent_platforms','released'])\n",
    "\n",
    "# There is no ESRB rating 0. We are using it for games that lacked a rating.\n",
    "df['esrb_rating.id'] = df['esrb_rating.id'].fillna(0)\n",
    "\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43420a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many null values are left, important to remove before attempting machine learning.\n",
    "df_columns = df.columns.tolist()\n",
    "for column in df_columns:\n",
    "    if df[column].isnull().sum() != 0:\n",
    "        print (column)\n",
    "        print(df[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Boris' eyes only.\n",
    "df.to_csv('boris_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70402c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df, columns=[\"owners\"],drop_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
